#首先声明一个Checkpoint

checkpoint=tf.train.Checkpoint(model=model)

#tf.train.Checkpoint()接受的初始化参数比较特殊，是一个**kwargs，具体而言，是一系列的键值对，键名可以随意取，值为需要保存的对象。
#例如，保存一个继承tf.keras.Model的模型实例model和一个继承tf.train.Optimizer的优化器optimizer，

checkpoint=tf.train.Checkpoint(myAwesomeModel=model,myAwesomeOptimizer=optimizer)

#这里的myAwesomeModel是我们为待保存的模型model所取的任意键名。
#注意，在恢复变量的时候，还要使用这一键名
#接下来，当模型训练完需要保存的时候，使用：

checkpoint.save(save_path_with_prefix)

#例如，在源代码目录建立一个名为save的文件夹并调用一次checkpoint.save('./save/model.ckpt')
#我们就可以在可以在 save 目录下发现名为checkpoint 、model.ckpt-1.index 、model.ckpt-1.data-00000-of-00001 的三个文件,
#这些文件就记录了变量信息。
#checkpoint.save() 方法可以运行多次,每运行一次都会得到一个.index 文件和.data 文件,序号依次累加。
#当在其他地方需要为模型重新载入之前保存的参数时,需要再次实例化一个 checkpoint,同时保持键名的一致。再调用 checkpoint 的 restore 方法。

model_to_be_restored=MyModel()    #待3恢复参数的同一模型
checkpoint=tf.train.Checkpoint(myAwesomeModel=model_to_be_restored)
checkpoint.restore(save_path_with_prefix_and_index)

#save_path_with_prefix_and_index 是之前保存的文件的目录 + 前缀 + 编号。
#调用 checkpoint.restore('./save/model.ckpt-1') 就可以载入前缀为 model.ckpt ,序号为 1 的文件来恢复模型。



###
#总体而言，恢复与保存变量的典型代码框架如下：
###

#在模型训练阶段：

model=MyModel()
checkpoint=tf.train.Checkpoint(myModel=model)#实例化checkpoint，指定保存对象为model（如果需要保存Optimizer的参数也可以加入）
#模型训练代码
checkpoint.save('./save/model.ckpt')#可以在模型训练结束后将参数保存到文件，也可以在模型训练过程中每隔一段时间就保存一次

#在模型使用阶段：

model=MyModel()
checkpoint=tf.train.Checkpoint(myModel=model)#实例化checkpoint，指定保存对象为model
checkpoint.restore(tf.train.latest_checkpoint('./save'))
#模型使用代码

